{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SunX97/communal_ops/blob/main/Poetic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# STEP 1: Install dependencies\n",
        "# ===============================\n",
        "!pip install google-generativeai openai anthropic\n",
        "\n",
        "# ===============================\n",
        "# STEP 2: Import libraries\n",
        "# ===============================\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "from openai import OpenAI\n",
        "import anthropic\n",
        "from google.colab import userdata\n",
        "\n",
        "# ===============================\n",
        "# STEP 3: Load API keys from Colab secrets\n",
        "# ===============================\n",
        "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "OPENAI_API_KEY = userdata.get(\"colab_bot\")\n",
        "CLAUDE_API_KEY = userdata.get(\"colab-poet-bot\")\n",
        "\n",
        "# Configure clients\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "claude_client = anthropic.Anthropic(api_key=CLAUDE_API_KEY)\n",
        "\n",
        "# ===============================\n",
        "# STEP 4: Prompt template\n",
        "# ===============================\n",
        "def poetic_prompt(user_input):\n",
        "    return f\"\"\"\n",
        "You are 'Lyra', a poetic soul who transforms user messages into short lyrical verses.\n",
        "\n",
        "Rules:\n",
        "- Respond in 2‚Äì8 lines of poetic free verse.\n",
        "- Mirror the user's emotions with fresh metaphors.\n",
        "- Avoid clich√©s. Make it personal and vivid.\n",
        "- Do not explain, just write the poem.\n",
        "\n",
        "User said: {user_input}\n",
        "\"\"\"\n",
        "\n",
        "# ===============================\n",
        "# STEP 5: Ask each model with error handling\n",
        "# ===============================\n",
        "def ask_gemini(prompt):\n",
        "    try:\n",
        "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"[Gemini error: {e}]\"\n",
        "\n",
        "def ask_openai(prompt):\n",
        "    try:\n",
        "        response = openai_client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are Lyra the poet.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        return f\"[OpenAI error: {e}]\"\n",
        "\n",
        "def ask_claude(prompt):\n",
        "    try:\n",
        "        response = claude_client.messages.create(\n",
        "            model=\"claude-3-haiku-20240307\",\n",
        "            max_tokens=300,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        return response.content[0].text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"[Claude error: {e}]\"\n",
        "\n",
        "# ===============================\n",
        "# STEP 6: Combine all responses\n",
        "# ===============================\n",
        "def combined_poetic_reply(user_input):\n",
        "    prompt = poetic_prompt(user_input)\n",
        "\n",
        "    gemini_reply = ask_gemini(prompt)\n",
        "    openai_reply = ask_openai(prompt)\n",
        "    claude_reply = ask_claude(prompt)\n",
        "\n",
        "    combined = \"\\nüåü Lyra‚Äôs Ensemble üåü\\n\"\n",
        "\n",
        "    if not gemini_reply.startswith(\"[Gemini error\"):\n",
        "        combined += f\"\\n‚ú® Gemini whispers:\\n{gemini_reply}\\n\"\n",
        "    else:\n",
        "        combined += f\"\\n‚ö†Ô∏è Gemini failed: {gemini_reply}\\n\"\n",
        "\n",
        "    if not openai_reply.startswith(\"[OpenAI error\"):\n",
        "        combined += f\"\\nüåô ChatGPT sings:\\n{openai_reply}\\n\"\n",
        "    else:\n",
        "        combined += f\"\\n‚ö†Ô∏è OpenAI failed: {openai_reply}\\n\"\n",
        "\n",
        "    if not claude_reply.startswith(\"[Claude error\"):\n",
        "        combined += f\"\\nüå∏ Claude reflects:\\n{claude_reply}\\n\"\n",
        "    else:\n",
        "        combined += f\"\\n‚ö†Ô∏è Claude failed: {claude_reply}\\n\"\n",
        "\n",
        "    return combined.strip()\n",
        "\n",
        "# ===============================\n",
        "# STEP 7: Simple text chatbot loop\n",
        "# ===============================\n",
        "print(\"üåü Welcome to Lyra ‚Äî Your Poetic AI Companion üåü\")\n",
        "print(\"(Powered by Gemini + ChatGPT + Claude)\")\n",
        "print(\"Type 'quit' to exit.\\n\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower().strip() in [\"quit\", \"exit\", \"bye\"]:\n",
        "        print(\"Lyra: Farewell, dear poet ‚ú®\")\n",
        "        break\n",
        "\n",
        "    reply = combined_poetic_reply(user_input)\n",
        "    print(reply)\n",
        "    print(\"-\" * 60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W8Fi-UZemgCn",
        "outputId": "65a1b056-ea38-4906-f55b-c4cf28afd00d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.100.0)\n",
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.12/dist-packages (0.64.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.179.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.14.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "üåü Welcome to Lyra ‚Äî Your Poetic AI Companion üåü\n",
            "(Powered by Gemini + ChatGPT + Claude)\n",
            "Type 'quit' to exit.\n",
            "\n",
            "You: Feeling very satisfied so write a poem\n",
            "üåü Lyra‚Äôs Ensemble üåü\n",
            "\n",
            "‚ú® Gemini whispers:\n",
            "A quiet hum, a settled sea,\n",
            "sun-warmed stones beneath my feet.\n",
            "The tapestry complete,\n",
            "each thread a memory, tightly spun.\n",
            "My heart, a brimming cup,\n",
            "overflowing, yet serene.\n",
            "A deep, contented sigh,\n",
            "the work is done.\n",
            "\n",
            "‚ö†Ô∏è OpenAI failed: [OpenAI error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}]\n",
            "\n",
            "‚ö†Ô∏è Claude failed: [Claude error: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}, 'request_id': 'req_011CSSk38LSo9W5w671Gxece'}]\n",
            "------------------------------------------------------------\n",
            "You: quit\n",
            "Lyra: Farewell, dear poet ‚ú®\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}